{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics  \n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#########部分SKLearn 集成的算法###############\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree  \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from xgboost import XGBClassifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "%matplotlib inline\n",
    "#########SKLearn 集成的算法###############\n",
    "############全局参数#################################\n",
    "id_col_names=['user_id','coupon_id','date_received']\n",
    "target_col_name='label'\n",
    "id_target_cols=['user_id','coupon_id','date_received','label']\n",
    "myeval='roc_auc'\n",
    "pred_result_col='predicted'\n",
    "#cvscore=0\n",
    "############目录定义#################################\n",
    "datapath = '../data/' \n",
    "featurepath = '../feature/' \n",
    "resultpath = '../result/'\n",
    "tmppath = '../tmp/'\n",
    "scorepath = '../score/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########工具函数#############################################\n",
    "#返回ID列\n",
    "def get_id_df(df):\n",
    "    return df[id_col_names]\n",
    "\n",
    "#返回Target列\n",
    "def get_target_df(df):\n",
    "    return df[target_col_name]\n",
    "\n",
    "#返回特征列\n",
    "def get_predictors_df(df):\n",
    "    predictors = [f for f in df.columns if f not in id_target_cols]\n",
    "    return df[predictors]\n",
    "\n",
    "#按特征名读取训练集\n",
    "def read_featurefile_train(featurename): \n",
    "    df=pd.read_csv(featurepath+'train_'+featurename+'.csv', sep=',' , encoding = \"utf-8\")\n",
    "    df.fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "#按特征名读取测试集\n",
    "def read_featurefile_test(featurename): \n",
    "    df=pd.read_csv(featurepath+'test_'+featurename+'.csv', sep=',' , encoding = \"utf-8\")\n",
    "    df.fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 将特征归一化\n",
    "def standize_df(train_data,test_data):\n",
    "    from sklearn import preprocessing \n",
    "    \n",
    "    features_columns = [f for f in test_data.columns if f not in id_target_cols]\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    min_max_scaler = min_max_scaler.fit(train_data[features_columns])\n",
    "    \n",
    "    train_data_scaler = min_max_scaler.transform(train_data[features_columns])\n",
    "    test_data_scaler = min_max_scaler.transform(test_data[features_columns])\n",
    "    \n",
    "    train_data_scaler = pd.DataFrame(train_data_scaler)\n",
    "    train_data_scaler.columns = features_columns\n",
    "    \n",
    "    test_data_scaler = pd.DataFrame(test_data_scaler)\n",
    "    test_data_scaler.columns = features_columns\n",
    "    \n",
    "    train_data_scaler['label'] = train_data['label']\n",
    "    train_data_scaler[id_col_names] = train_data[id_col_names]\n",
    "    test_data_scaler[id_col_names] = test_data[id_col_names]\n",
    "    return train_data_scaler,test_data_scaler\n",
    "\n",
    "#按特征名读取数据\n",
    "def read_data(featurename): \n",
    "    traindf = read_featurefile_train(featurename)\n",
    "    testdf = read_featurefile_test(featurename)\n",
    "    #return traindf,testdf  \n",
    "    return standize_df(traindf,testdf)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################使用sklearn的统一代码框架##########################\n",
    "#提供的函数包括：\n",
    "#classifier_single(featurename,classifier,cvnum)\n",
    "#按满减情况分别预测\n",
    "#classifier_single_sep_fd(featurename,classifier,cvnum): \n",
    "####################整合在sklearn的分类算法###############\n",
    "def get_sklearn_model(model_name,param=None):\n",
    "    #朴素贝叶斯\n",
    "    if model_name=='NB':\n",
    "        model = MultinomialNB(alpha=0.01)\n",
    "    #逻辑回归\n",
    "    elif model_name=='LR':\n",
    "        model = LogisticRegression(penalty='l2') \n",
    "    # KNN  \n",
    "    elif model_name=='KNN':\n",
    "        model = KNeighborsClassifier()  \n",
    "    #随机森林\n",
    "    elif model_name=='RF':\n",
    "        model = RandomForestClassifier()  \n",
    "    #决策树\n",
    "    elif model_name=='DT':\n",
    "        model = tree.DecisionTreeClassifier()  \n",
    "    #向量机\n",
    "    elif model_name=='SVC':\n",
    "        model = SVC(kernel='rbf')\n",
    "    #GBDT\n",
    "    elif model_name=='GBDT':\n",
    "        model = GradientBoostingClassifier()\n",
    "    #XGBoost\n",
    "    elif model_name=='XGB':\n",
    "        model = XGBClassifier()\n",
    "    #lightGBM\n",
    "    elif model_name=='LGB':\n",
    "        model = LGBMClassifier()\n",
    "    else:\n",
    "        print(\"wrong model name!\")\n",
    "        return\n",
    "    if param is not None:\n",
    "        model.set_params(**param)\n",
    "    return model\n",
    "    \n",
    "\n",
    "#性能评价函数\n",
    "#本赛题目标是预测投放的优惠券是否核销。\n",
    "#针对此任务及一些相关背景知识，使用优惠券核销预测的平均AUC（ROC曲线下面积）作为评价标准。 \n",
    "#即对每个优惠券coupon_id单独计算核销预测的AUC值，再对所有优惠券的AUC值求平均作为最终的评价标准。\n",
    "# coupon平均auc计算\n",
    "def myauc(test):\n",
    "    testgroup = test.groupby(['coupon_id'])\n",
    "    aucs = []\n",
    "    for i in testgroup:\n",
    "        coupon_df = i[1]\n",
    "        #测算AUC必须大于1个类别\n",
    "        if len(coupon_df['label'].unique()) < 2:\n",
    "            continue\n",
    "        auc = metrics.roc_auc_score(coupon_df['label'], coupon_df['predicted'])\n",
    "        aucs.append(auc)\n",
    "    return np.average(aucs)\n",
    "\n",
    "#预测方式：按照购买概率进行预测\n",
    "def proba_predict(model,df):\n",
    "    pred = model.predict_proba(df)\n",
    "    return pred[:,1] \n",
    "\n",
    "#预测，\n",
    "def classifier_pred(traindf,classifier,param=None):\n",
    "    model = get_sklearn_model(classifier,param)\n",
    "    if classifier in ['LGB']:\n",
    "        model.fit(get_predictors_df(traindf), get_target_df(traindf),eval_metric=myeval)\n",
    "    if classifier in ['XGB']:\n",
    "        model.fit(get_predictors_df(traindf), get_target_df(traindf),eval_metric='auc')\n",
    "    else:\n",
    "        model.fit(get_predictors_df(traindf), get_target_df(traindf))\n",
    "    return model\n",
    "\n",
    "#不分折进行预测\n",
    "def fit_once(train_feat, test_feat,classifier,param=None):\n",
    "    model=classifier_pred(train_feat,classifier,param)\n",
    "    predicted = pd.DataFrame(proba_predict(model,get_predictors_df(test_feat)))\n",
    "    return predicted,get_target_df(train_feat)\n",
    "\n",
    "#分折进行预测\n",
    "def fit_cv(train_feat, test_feat,classifier,cvnum,param=None):       \n",
    "    print('开始CV '+str(cvnum)+'折训练...')\n",
    "    train_preds = np.zeros(train_feat.shape[0])\n",
    "    test_preds = np.zeros((test_feat.shape[0], cvnum))\n",
    "    i=0\n",
    "    kf = StratifiedKFold(n_splits = cvnum, shuffle=True, random_state=520)\n",
    "    for train_index, test_index in kf.split(get_predictors_df(train_feat),get_target_df(train_feat)):\n",
    "        print('第{}次训练...'.format(i+1))\n",
    "        train_feat1 = train_feat.iloc[train_index]\n",
    "        train_feat2 = train_feat.iloc[test_index]\n",
    "        model=classifier_pred(train_feat1,classifier,param)\n",
    "        \n",
    "        train_preds[test_index] += proba_predict(model,get_predictors_df(train_feat2))\n",
    "        test_preds[:,i] = proba_predict(model,get_predictors_df(test_feat))\n",
    "        i=i+1\n",
    "    \n",
    "#    print('CV训练用时{}秒'.format(time.time() - t0))\n",
    "    test_y=test_preds.mean(axis=1)    \n",
    "    #test_y_1 = pd.Series(test_y).apply(lambda x : 1 if x>0.5 else 0)\n",
    "    #submission = pd.DataFrame({'pred':test_preds.mean(axis=1)})\n",
    "    return pd.DataFrame(test_y),pd.DataFrame(train_preds)\n",
    "\n",
    "\n",
    "def classifier_df(train_feat, test_feat,classifier,cvnum,param=None): \n",
    "    if cvnum<=1:\n",
    "        predicted,train_preds = fit_once(train_feat, test_feat,classifier,param)\n",
    "    else:\n",
    "        predicted,train_preds = fit_cv(train_feat,test_feat,classifier,cvnum,param)\n",
    "    print('output')\n",
    "    #predicted=predicted.round(3)\n",
    "    return predicted,train_preds\n",
    "\n",
    "#输出结果\n",
    "def output_predicted(predicted,resultfile,test_feat):\n",
    "    predicted=round(predicted,3)\n",
    "    resultdf=get_id_df(test_feat).copy()\n",
    "    resultdf['Probability']=predicted\n",
    "    resultdf.to_csv(resultfile,header=False,index=False,sep=',')\n",
    "\n",
    "#预测函数\n",
    "def classifier_df_simple(train_feat, test_feat,classifier,param=None):\n",
    "    model = get_sklearn_model(classifier,param)    \n",
    "    model.fit(get_predictors_df(train_feat), get_target_df(train_feat))    \n",
    "    predicted = pd.DataFrame(model.predict_proba(get_predictors_df(test_feat))[:,1])\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################训练曲线################################################\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=[0.005,0.01,0.02,0.04,0.1,0.2,0.5]):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv,scoring=myeval, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    " \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    " \n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "#画算法的学习曲线,为加快画图速度，最多选30%数据\n",
    "def plot_curve_single(featurename,classifier,cvnum,train_sizes=[0.002,0.005,0.01,0.02,0.05,0.1,0.2,0.3]): \n",
    "    traindf,testdf= read_data(featurename)\n",
    "    X=get_predictors_df(traindf)\n",
    "    y=get_target_df(traindf)\n",
    "    title = \"learning curve of feature:\"+featurename+\", model \"+classifier+\", cv:\"+str(cvnum)\n",
    "    estimator = get_sklearn_model(classifier)    #建模\n",
    "    plot_learning_curve(estimator, title, X, y, ylim=(0, 1.01), cv=cvnum, train_sizes=train_sizes)\n",
    "##########################算法分析###############################################  \n",
    "#对算法进行分析整体AUC\n",
    "def classifier_df_score_auc(train_x,train_y,classifier,cvnum,param=None):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    model=get_sklearn_model(classifier,param)\n",
    "    #loss  = make_scorer(my_custom_loss_func, greater_is_better=False)\n",
    "    #score = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "    scores = cross_val_score(model,train_x,train_y,scoring=myeval,cv=cvnum)\n",
    "    return scores\n",
    "    \n",
    "def classifier_single_score(featurename,classifier,cvnum,param=None): \n",
    "    print('reading training data...')\n",
    "    traindf,testdf= read_data(featurename)\n",
    "    train_x=get_predictors_df(traindf)\n",
    "    train_y=get_target_df(traindf)\n",
    "    scores=classifier_df_score(train_x,train_y,classifier,cvnum,param)\n",
    "    print(scores)\n",
    "    print(classifier+\":\")\n",
    "    print(scores.mean())\n",
    " \n",
    "#对算法进行分析Coupon AUC\n",
    "def classifier_df_score(train_feat,classifier,cvnum,param=None):  \n",
    "    clf=get_sklearn_model(classifier,param)\n",
    "    train = train_feat.copy()\n",
    "    target = get_target_df(train_feat).copy()\n",
    "    kf = StratifiedKFold(n_splits=cvnum)\n",
    "    \n",
    "    scores=[]\n",
    "    score_coupons=[]\n",
    "    for k, (train_index, test_index) in enumerate(kf.split(train,target)):\n",
    "        train_data,test_data,train_target,test_target = train.iloc[train_index],train.iloc[test_index],target[train_index],target[test_index]\n",
    "        clf.fit(get_predictors_df(train_data), train_target) \n",
    "        \n",
    "        test_pred=clf.predict_proba(get_predictors_df(test_data))[:,1]\n",
    "        \n",
    "        score_test = metrics.roc_auc_score(test_target, test_pred)\n",
    "        test_data[pred_result_col]=test_pred\n",
    "        score_coupon_test=myauc(test_data)\n",
    "        \n",
    "        scores.append(score_test)\n",
    "        score_coupons.append(score_coupon_test)\n",
    "        \n",
    "    print (classifier+\"总体AUC:\",scores)\n",
    "    print (classifier+\"Coupon AUC:\",score_coupons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################网格调参###############################################\n",
    "#对进行网格调参\n",
    "def grid_search(train_feat, test_feat,classifier,cvnum,search_scope,param=None):\n",
    "    parameters= search_scope\n",
    "    clf = GridSearchCV(get_sklearn_model(classifier,param), \n",
    "        param_grid=parameters,scoring='roc_auc',verbose=2)\n",
    "    clf.fit(get_predictors_df(train_feat), get_target_df(train_feat))\n",
    "    print(\"最优参数\")\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    test_df=get_predictors_df(test_feat)\n",
    "    predicted = pd.DataFrame(clf.predict(test_df))\n",
    "    return predicted\n",
    "\n",
    "def grid_search_single(featurename,classifier,cvnum,search_scope,param=None):\n",
    "    train_feat,test_feat= read_data(featurename)\n",
    "    predicted=grid_search(train_feat, test_feat,classifier,cvnum,search_scope,param)\n",
    "    resultfile=resultpath+featurename+'_'+str(cvnum)+'_'+classifier+'_grid_'+format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))+'.csv'\n",
    "    output_predicted(predicted,resultfile,test_feat)\n",
    "    \n",
    "#对进行网格调参\n",
    "def grid_plot(train_feat,classifier,cvnum,param_range,param_name,param=None):\n",
    "    from sklearn.model_selection import validation_curve\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        get_sklearn_model(classifier,param), get_predictors_df(train_feat), get_target_df(train_feat), param_name=param_name, param_range=param_range,\n",
    "        cv=cvnum, scoring='roc_auc', n_jobs=1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.title(\"Validation Curve with \"+param_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    plt.semilogx(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "    plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"g\")\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "def grid_plot_single(featurename,classifier,cvnum,param_range,param_name,param=None):\n",
    "    train_feat,test_feat= read_data(featurename)\n",
    "    grid_plot(train_feat,classifier,cvnum,param_range,param_name,param=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################以下为最终输出函数##########################################\n",
    "#只运行一种算法\n",
    "def classifier_single(featurename,classifier,cvnum,param=None): \n",
    "    traindf,testdf= read_data(featurename)\n",
    "    \n",
    "    predicted,train_preds=classifier_df(traindf,testdf,classifier,cvnum,param)\n",
    "    \n",
    "    if cvnum>1:\n",
    "        traindf[pred_result_col]=train_preds    \n",
    "        score =myauc(traindf)\n",
    "        print('线下成绩：    {}'.format(score))\n",
    "        resultfile=resultpath+featurename+'_'+str(cvnum)+'_'+classifier+'_'+format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))+'_'+str(round(score,3))+'.csv'\n",
    "    else:\n",
    "        resultfile=resultpath+featurename+'_'+str(cvnum)+'_'+classifier+'_'+format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))+'.csv'\n",
    "    output_predicted(predicted,resultfile,testdf)\n",
    "\n",
    "# 平均融合classifier_multi的一种融合方式，可以写多个类似的,作为classifier_multi的参数\n",
    "def multi_mean(train_multi,test_multi,pred_names):\n",
    "    i=0\n",
    "    for pred in pred_names:\n",
    "        i=i+1\n",
    "        if i==1:\n",
    "            train_multi[pred_result_col]=train_multi[pred]\n",
    "            test_multi[pred_result_col]=test_multi[pred]\n",
    "        else:\n",
    "            train_multi[pred_result_col]=train_multi[pred_result_col]+train_multi[pred]\n",
    "            test_multi[pred_result_col]=train_multi[pred_result_col]+test_multi[pred]\n",
    "    train_multi[pred_result_col]=train_multi[pred_result_col]/i\n",
    "    test_multi[pred_result_col]=test_multi[pred_result_col]/i\n",
    "    return train_multi,test_multi\n",
    "   \n",
    "#运行多种算法\n",
    "#sum_func为对多种算法结果的整合函数，要求最终的输出列为'predicted'\n",
    "def classifier_multi(featurename,classifiers,cvnum,sum_func,param=None): \n",
    "    traindf,testdf= read_data(featurename)\n",
    "    train_multi=traindf.copy()\n",
    "    test_multi=testdf.copy()\n",
    "    \n",
    "    notes=''\n",
    "    pred_names=[]\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        print('开始'+classifier+'训练')\n",
    "        notes=notes+'-'+classifier\n",
    "        pred_names.append(classifier+'_pred')\n",
    "        predicted,train_preds=classifier_df(traindf,testdf,classifier,cvnum,param)\n",
    "        train_multi[classifier+'_pred']=train_preds\n",
    "        test_multi[classifier+'_pred']=predicted\n",
    "    \n",
    "    train_result,test_result=sum_func(train_multi,test_multi,pred_names)\n",
    "\n",
    "    #score = metrics.roc_auc_score(get_target_df(train_result),train_result['predicted'])\n",
    "    #print('线下得分：    {}'.format(score))\n",
    "    \n",
    "    score =myauc(train_result)\n",
    "    print('线下成绩：    {}'.format(score))\n",
    "\n",
    "    if cvnum>1:\n",
    "        resultfile=resultpath+featurename+'_'+str(cvnum)+'_'+notes+'_'+format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))+'_'+str(round(score,3))+'.csv'\n",
    "    else:\n",
    "        resultfile=resultpath+featurename+'_'+str(cvnum)+'_'+notes+'_'+format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S'))+'.csv'\n",
    "    \n",
    "    output_predicted(test_result['predicted'],resultfile,test_result)\n",
    "\n",
    "#按满减情况分别预测\n",
    "def classifier_single_sep_fd(featurename,classifier,cvnum,param=None): \n",
    "    trainalldf,testalldf= read_data(featurename)\n",
    "    test_result=pd.DataFrame()\n",
    "    train_result=pd.DataFrame()\n",
    "    #按满减情况分类\n",
    "    for fd in range(0,2):\n",
    "        traindf=trainalldf[trainalldf.if_fd==fd].copy()\n",
    "        testdf=testalldf[testalldf.if_fd==fd].copy()\n",
    "       \n",
    "        predicted,train_preds=classifier_df(traindf,testdf,classifier,cvnum,param)\n",
    "        predicted=round(predicted,3)\n",
    "\n",
    "        if fd==0:\n",
    "            test_result=get_id_df(testdf).copy().reset_index(drop=True)\n",
    "            test_result['predicted']=predicted\n",
    "            \n",
    "            train_result=traindf.copy().reset_index(drop=True)\n",
    "            train_result['predicted']=train_preds\n",
    "            \n",
    "        else:\n",
    "            dft1=get_id_df(testdf).copy().reset_index(drop=True)\n",
    "            dft1['predicted']=predicted\n",
    "            test_result=pd.concat([test_result,dft1], axis=0).reset_index(drop=True)\n",
    "            \n",
    "            dfv1=traindf.copy().reset_index(drop=True)\n",
    "            dfv1['predicted']=train_preds\n",
    "            train_result=pd.concat([train_result,dfv1], axis=0).reset_index(drop=True)\n",
    "\n",
    "    if cvnum>1:\n",
    "        #score = metrics.roc_auc_score(get_target_df(train_result),train_result['predicted'])\n",
    "        score = round(myauc(train_result),3)\n",
    "        print('线下得分：    {}'.format(score))    \n",
    "        resultfile=resultpath+featurename+'_sepfd_'+str(cvnum)+'_'+classifier+'_'+str(score)+'.csv'\n",
    "    else:\n",
    "        resultfile=resultpath+featurename+'_sepfd_'+str(cvnum)+'_'+classifier+'.csv'\n",
    "    test_result.to_csv(resultfile,header=False,index=False,sep=',')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用f2版本特征，LightGBM，5折，默认参数\n",
    "classifier_single('sf2','LGB',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用f3版本特征，LightGBM，5折，默认参数\n",
    "classifier_single('sf3','LGB',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用f3版本特征，LightGBM，5折，优化后参数\n",
    "\n",
    "params={'boosting_type':'gbdt',\n",
    "\t    'objective': 'binary',\n",
    "\t    'eval_metric':'auc',\n",
    "\t    'n_estimators':200,\n",
    "\t    'max_depth':5,\n",
    "\t    'num_leaves':40,\n",
    "\t    'max_bin':400,\n",
    "\t    'min_data_in_leaf':120,\n",
    "\t    'learning_rate':0.05,\n",
    "\t    'lambda_l1': 1e-05,\n",
    "\t    'lambda_l2':1e-05,\n",
    "\t    'min_split_gain':0.0,\n",
    "\t    'bagging_freq':4,\n",
    "\t    'bagging_fraction': 0.9,\n",
    "\t    'feature_fraction':0.6,\n",
    "\t    'seed':1024,\n",
    "\t    'n_thread':12\n",
    "\t    }\n",
    "classifier_single('sf3','LGB',5,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用f3版本特征，LightGBM+XGBoost融合，5折，默认参数\n",
    "classifier_multi('sf3',['XGB','LGB'],5,multi_mean)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e23aaff088e684ded1cdb3cfabf86e8de836efc7385bae0e194206f14ee28b5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
